{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from geopy.distance import geodesic\n",
    "from tqdm import tqdm\n",
    "import openrouteservice\n",
    "import polyline\n",
    "\n",
    "import random\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import ast\n",
    "import re\n",
    "\n",
    "\n",
    "hospital_df = pd.read_csv('../destinations/data/Hospitals.csv')\n",
    "airport_df = pd.read_csv('../destinations/data/Alt_Airports.csv')\n",
    "landmark_df = pd.read_csv('../destinations/data/Landmarks.csv')\n",
    "gov_building_df = pd.read_csv('../destinations/data/Landmarks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to choose to and fro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Name         RAYMOND G. MURPHY VA MEDICAL CENTER\n",
      "City                                 ALBUQUERQUE\n",
      "State                                         NM\n",
      "Longitude                            -106.581767\n",
      "Latitude                               35.055168\n",
      "Name: 112, dtype: object, Name         Las Vegas Municipal Airport\n",
      "City                           LAS VEGAS\n",
      "State                                 NM\n",
      "Longitude                    -105.141998\n",
      "Latitude                       35.654202\n",
      "Name: 577, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This currently uses rejection sampling to find points that are less than\n",
    "# 150km apart. If this is used to generate a larger dataset, this needs to\n",
    "# be refactored to generate pairs on initialization, and/or use a spatial\n",
    "# database to improve performance.\n",
    "\n",
    "class ToAndFroGenerator:\n",
    "    def __init__(self, dataframes: List[pd.DataFrame], frequencies: List[float] = None):\n",
    "\n",
    "        if frequencies != None and len(dataframes) != len(frequencies):\n",
    "            raise ValueError(\"dataframes and numbers lists must have the same length\")\n",
    "        \n",
    "        # Default to uniform if no distribution is provided\n",
    "        if frequencies is None:\n",
    "            frequencies = [1] * len(dataframes)\n",
    "\n",
    "        # Set up upper bounds for choosing the source dataframes randomly\n",
    "        s = 0.0\n",
    "        self.__random_dataframe_upper_bounds = []\n",
    "        for n in frequencies:\n",
    "            s += n\n",
    "            self.__random_dataframe_upper_bounds.append(s)\n",
    "        \n",
    "        self.__dataframes = dataframes\n",
    "        self.__random_dataframe_max_number = sum(frequencies)\n",
    "        self.__seen = set()\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_to_and_fro(self):\n",
    "        n1 = random.uniform(0, self.__random_dataframe_max_number)\n",
    "        n2 = random.uniform(0, self.__random_dataframe_max_number)\n",
    "\n",
    "        # Finding the indices of the dataframes that we are getting the points from\n",
    "        i, from_idx, to_idx = 0, -1, -1\n",
    "        for n in self.__random_dataframe_upper_bounds:\n",
    "            if n1 <= n:\n",
    "                from_idx = i\n",
    "                break\n",
    "            i += 1\n",
    "        i = 0\n",
    "        for n in self.__random_dataframe_upper_bounds:\n",
    "            if n2 <= n:\n",
    "                to_idx = i\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        assert from_idx != -1 and to_idx != -1, \"logic error: failed to randomly select dataframe for to and fro\"\n",
    "\n",
    "        \n",
    "        for _ in range(10):\n",
    "            # Randomly select the two datapoints\n",
    "            from_row = self.__dataframes[from_idx].sample(n=1).iloc[0]\n",
    "\n",
    "            # Get points in the same state\n",
    "            filtered =  self.__dataframes[to_idx][self.__dataframes[to_idx]['State'] == from_row['State']]\n",
    "            if filtered.empty:\n",
    "                return (None, None)\n",
    "            to_row = filtered.sample(n=1).iloc[0]\n",
    "\n",
    "            # Check to make sure to isn't the same as from\n",
    "            if (to_row.equals(from_row)):\n",
    "                    continue\n",
    "\n",
    "            # Filter out points with distance > 150 km\n",
    "            distance = geodesic((from_row['Latitude'], from_row['Longitude']), \n",
    "                                (to_row['Latitude'], to_row['Longitude'])).km\n",
    "            if distance >= 150:\n",
    "                continue\n",
    "\n",
    "            # Check against seen pairs for uniqueness\n",
    "            encoded_tuple = f\"{from_row['Longitude']} {from_row['Latitude']} {to_row['Longitude']} {to_row['Latitude']}\"\n",
    "            if encoded_tuple in self.__seen:\n",
    "                continue\n",
    "            else:\n",
    "                self.__seen.add(encoded_tuple)\n",
    "                return (to_row, from_row)\n",
    "        \n",
    "        # If no unique pair is found after 10 tries, return None\n",
    "        return (None, None)\n",
    "    \n",
    "# Simple test\n",
    "obj = ToAndFroGenerator([hospital_df, airport_df], [1, 1])\n",
    "\n",
    "print(obj.get_to_and_fro())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for printing to stderr\n",
    "# This is for running on RC servers\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)\n",
    "\n",
    "\n",
    "def get_directions(from_row, to_row, ors_client, valhalla_url=\"http://localhost:8002\"): \n",
    "\n",
    "    plans = []\n",
    "    detailed_plans = []\n",
    "\n",
    "    # Avoid rate limit\n",
    "    time.sleep(1)\n",
    "\n",
    "    try:\n",
    "        # Query directions\n",
    "        data = ors_client.directions(\n",
    "            coordinates = [\n",
    "                [from_row['Longitude'], from_row['Latitude']],\n",
    "                [to_row['Longitude'], to_row['Latitude']]\n",
    "            ],\n",
    "            profile = 'driving-car',\n",
    "            alternative_routes = {\n",
    "                'target_count': 3\n",
    "            },\n",
    "        )\n",
    "    except:\n",
    "        return (None, None)\n",
    "    \n",
    "    for route in data['routes']:\n",
    "        decoded_geometry = polyline.decode(route['geometry'])\n",
    "\n",
    "        # print(decoded_geometry)\n",
    "        \n",
    "        points = []\n",
    "\n",
    "        for point in decoded_geometry:\n",
    "            points.append({\n",
    "                'lat': point[0],\n",
    "                'lon': point[1],\n",
    "            })\n",
    "        \n",
    "        payload = {\n",
    "            \"shape\": points,\n",
    "            \"costing\": \"auto\",\n",
    "            \"shape_match\": \"map_snap\",\n",
    "            \"directions_options\": {\"units\": \"kilometers\"},\n",
    "        }\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "        response = requests.post(valhalla_url + '/trace_route', json=payload, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            route = response_data['trip']['legs'][0]['maneuvers']\n",
    "\n",
    "            # Decode the new polyline:\n",
    "            decoded_geometry = polyline.decode(response_data['trip']['legs'][0]['shape'])\n",
    "\n",
    "            instructions = []\n",
    "            detailed_instructions = []\n",
    "\n",
    "            for step in route:\n",
    "                instructions.append(step['instruction'])\n",
    "\n",
    "                # Get location data for step\n",
    "                location = None\n",
    "                if 'begin_shape_index' in step and decoded_geometry and step['begin_shape_index'] < len(decoded_geometry):\n",
    "                    point_index = step['begin_shape_index']\n",
    "                    location = {\n",
    "                        'lat': round(decoded_geometry[point_index][0] / 10, 6),\n",
    "                        'lon': round(decoded_geometry[point_index][1] / 10, 6),\n",
    "                    }\n",
    "                \n",
    "                # Create detailed instruction dict\n",
    "                detailed_instruction = {\n",
    "                    'instruction': step['instruction'],\n",
    "                    'name': step['street_names'][0] if step.get('street_names') else '-', # Only take the primary name which is refered to in the instruction\n",
    "                    'alt_names': step['street_names'][1:] if step.get('street_names') and len(step['street_names']) > 1 else [], # Store the rest of the names\n",
    "                    'distance': step['length'] * 1000, # Get distance in meters\n",
    "                    'duration': step['time'], # Duration of step in seconds\n",
    "                    'type': step['type'], # Type can tell more about what the instruction is doing\n",
    "                }\n",
    "\n",
    "                # Only add location if one is provided\n",
    "                if location:\n",
    "                    detailed_instruction['location'] = location\n",
    "                \n",
    "                detailed_instructions.append(detailed_instruction)\n",
    "        else:\n",
    "            print(f\"Error (Valhalla): Received status code {response.status_code}\")\n",
    "            print(response.text)\n",
    "        plans.append(instructions)\n",
    "        detailed_plans.append(detailed_instructions)\n",
    "\n",
    "    return (plans, detailed_plans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data: 100%|██████████| 2/2 [00:10<00:00,  5.27s/entry]\n"
     ]
    }
   ],
   "source": [
    "columns = ['Domain', 'Goal', 'Plan']\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "count = 0\n",
    "total_iterations = 2\n",
    "\n",
    "generator = ToAndFroGenerator([hospital_df, airport_df, landmark_df, gov_building_df])\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPEN_ROUTE_SERVICE_API_KEY\")\n",
    "\n",
    "ors_client = openrouteservice.Client(key=API_KEY)\n",
    "\n",
    "with tqdm(total=total_iterations, desc=\"Generating Data\", unit=\"entry\") as pbar:\n",
    "    while count < total_iterations:\n",
    "        time.sleep(1)\n",
    "        (from_row, to_row) = generator.get_to_and_fro()\n",
    "\n",
    "        if from_row is None or to_row is None:\n",
    "            continue\n",
    "\n",
    "        (instructions, detailed_instructions) = get_directions(from_row=from_row, to_row=to_row, ors_client=ors_client)\n",
    "\n",
    "        # Either an error, or less than three routes\n",
    "        if not instructions or len(instructions) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Append new row to dataframe\n",
    "        new_row = pd.DataFrame([{\n",
    "            'id': int(count),\n",
    "            'Domain': f\"coordinates = [[{from_row['Longitude']},{from_row['Latitude']}],[{to_row['Longitude']},{to_row['Latitude']}],]\",\n",
    "            'Goal': f\"{from_row['Name']} ({from_row['City']}, {from_row['State']}) to {to_row['Name']} ({to_row['City']}, {to_row['State']})\",\n",
    "            'Plan': str(instructions),\n",
    "            'Detailed Plan': str(detailed_instructions),\n",
    "        }], columns=['id', 'Domain', 'Goal', 'Plan', 'Detailed Plan'])\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "        # Update count and progress bar\n",
    "        count += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "df\n",
    "\n",
    "df.to_csv('./output_data/intermediate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_instructions(row):\n",
    "    ambiguous_instructions = {\n",
    "        # Types 10 and 15\n",
    "        'Turn right.',\n",
    "        'Turn left.',\n",
    "        # Types 11 and 14\n",
    "        'Make a sharp right.',\n",
    "        'Make a sharp left.',\n",
    "        # Types 9 and 16\n",
    "        'Bear right.',\n",
    "        'Bear left.',\n",
    "        # Types 20 and 21\n",
    "        'Take the exit on the right.',\n",
    "        'Take the exit on the left.',\n",
    "        # Types 18 and 19\n",
    "        'Take the ramp on the right.',\n",
    "        'Take the ramp on the left.',\n",
    "        # Types 12 and 13\n",
    "        'Make a left U-turn.',\n",
    "        'Make a right U-turn.',\n",
    "    }\n",
    "    \n",
    "    for plan_idx in range(len(row['Plan'])):\n",
    "        plan = row['Plan'][plan_idx]\n",
    "        detailed_plan = row['Detailed Plan'][plan_idx]\n",
    "\n",
    "        indices_to_remove = set()\n",
    "        for step_idx in range(0, len(row['Plan'][plan_idx]) - 1):\n",
    "            step = detailed_plan[step_idx]\n",
    "            detailed_plan[step_idx]['has_interval'] = False\n",
    "\n",
    "            # Remove road directions from 'name' field\n",
    "            name = detailed_plan[step_idx]['name']\n",
    "            detailed_plan[step_idx]['name'] = re.sub(r'\\s+(South|North|East|West)$', '', name)\n",
    "\n",
    "            step_type = detailed_plan[step_idx]['type']\n",
    "            # Type == 26 and 27: Roundabouts\n",
    "            # These have a redundancy in their natural language representation\n",
    "            # so they will be merged into one step\n",
    "            if step_type == 26:\n",
    "                if detailed_plan[step_idx + 1]['type'] == 27:\n",
    "                    enter = detailed_plan[step_idx]\n",
    "                    exit = detailed_plan[step_idx + 1]\n",
    "                    enter['distance'] += exit['distance']\n",
    "                    enter['duration'] += exit['duration']\n",
    "                    enter['name'] = exit['name']\n",
    "                    enter['alt_names'] = exit['alt_names']\n",
    "\n",
    "                    indices_to_remove.add(step_idx + 1)\n",
    "\n",
    "                    detailed_plan[step_idx] = enter\n",
    "                else:\n",
    "                    print(\"Error: Entering roundabout without leaving\")\n",
    "\n",
    "            # Case where the instruction clearly lists a name for the ramp, but the data does not reflect it\n",
    "            if (step_type == 17 or step_type == 18 or step_type == 19) and detailed_plan[step_idx]['name'] == '-':\n",
    "                # Check for pattern in instruction (don't match on \"take the ramp\")\n",
    "                match = re.search(r'take the (.+?) ramp', detailed_plan[step_idx]['instruction'])\n",
    "                if match:\n",
    "                    # This means the ramp was given a name in the text representation\n",
    "                    detailed_plan[step_idx]['name'] = match.group(1)\n",
    "\n",
    "            # Adding distance and time to steps with identifying features to distinguish their location\n",
    "            instruction = detailed_plan[step_idx]['instruction']\n",
    "            if instruction in ambiguous_instructions and step_idx != 0:\n",
    "                distance = detailed_plan[step_idx - 1]['distance']\n",
    "                duration = detailed_plan[step_idx - 1]['duration']\n",
    "\n",
    "                interval = [round(duration - duration / 10), round(duration + duration / 10)]\n",
    "\n",
    "                # Remove period from old instruction\n",
    "                new_instruction = instruction[:-1]\n",
    "                if interval[0] == interval[1]:\n",
    "                    new_instruction += f\" after {round(distance)} meters or {interval[0]} seconds.\"\n",
    "                else:\n",
    "                    new_instruction += f\" after {round(distance)} meters or {interval[0]}-{interval[1]} seconds.\"\n",
    "\n",
    "                detailed_plan[step_idx]['instruction'] = new_instruction\n",
    "                plan[step_idx] = new_instruction\n",
    "\n",
    "                detailed_plan[step_idx]['has_interval'] = True\n",
    "                detailed_plan[step_idx]['interval'] = interval\n",
    "            \n",
    "        detailed_plan[len(detailed_plan) - 1]['has_interval'] = False\n",
    "\n",
    "        # Remove indices\n",
    "        plan = [step for idx, step in enumerate(plan) if idx not in indices_to_remove]\n",
    "        detailed_plan = [detail for idx, detail in enumerate(detailed_plan) if idx not in indices_to_remove]\n",
    "        \n",
    "        # Update row with new plans\n",
    "        row['Plan'][plan_idx] = plan\n",
    "        row['Detailed Plan'][plan_idx] = detailed_plan\n",
    "\n",
    "    return row\n",
    "\n",
    "df['Domain'] = df['Domain'].apply(lambda x: ast.literal_eval(x.replace('coordinates = ', '').strip()))\n",
    "df['Plan'] = df['Plan'].apply(ast.literal_eval)\n",
    "df['Detailed Plan'] = df['Detailed Plan'].apply(ast.literal_eval)\n",
    "\n",
    "df = df.apply(reformat_instructions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_order = ['id', 'Domain', 'Goal', 'Plan']\n",
    "\n",
    "df['Domain'] = df['Domain'].apply(lambda x: 'coordinates = ' + str(x))\n",
    "df['Plan'] = df['Plan'].apply(str)\n",
    "df['Detailed Plan'] = df['Detailed Plan'].apply(str)\n",
    "df['id'] = df['id'].apply(int)\n",
    "\n",
    "df.to_csv(\"./output_data/testing_generation.csv\",columns=column_order + ['Detailed Plan'], index=False)\n",
    "\n",
    "df = df.drop(columns=['Detailed Plan'])\n",
    "\n",
    "df.to_csv(\"./output_data/ajdfljasdfjkl.csv\", columns=column_order, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
